{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natual Language Processing\n",
    "\n",
    "- Import csv from scraping notebook\n",
    "- Binarize category column\n",
    "- combine title & body\n",
    "- stem and clean columns into engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laod libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data from previous notebook\n",
    "df = pd.read_csv('./data/raw_dict.csv', index_col =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making my category column binary\n",
    "df['cat_nums'] = df['category'].map({'conspiracy': 0,\n",
    "                                     'history': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new column with body and text\n",
    "df['pre_combined'] = df['text'].apply(lambda x: x if type(x)== str else '')\n",
    "df['combined'] =  df['title'] + df['pre_combined']\n",
    "# make new column for body or not\n",
    "df['binary_text'] = df['text'].apply(lambda x: 1 if type(x)== str else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unecessary columns\n",
    "df.drop(columns = ['pre_combined', 'category', 'text'], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cat_nums</th>\n",
       "      <th>combined</th>\n",
       "      <th>binary_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George Popadopoulos Judiciary Committee Transc...</td>\n",
       "      <td>0</td>\n",
       "      <td>George Popadopoulos Judiciary Committee Transc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scientists Will Spray Particles Into the Sky t...</td>\n",
       "      <td>0</td>\n",
       "      <td>Scientists Will Spray Particles Into the Sky t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We Are Change confronted Joe Biden in 2007 abo...</td>\n",
       "      <td>0</td>\n",
       "      <td>We Are Change confronted Joe Biden in 2007 abo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jeff Sessions swats creepy Uncle Joe's hands away</td>\n",
       "      <td>0</td>\n",
       "      <td>Jeff Sessions swats creepy Uncle Joe's hands away</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NXIVM cultist (üçï gate) admits to enslaving wom...</td>\n",
       "      <td>0</td>\n",
       "      <td>NXIVM cultist (üçï gate) admits to enslaving wom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  cat_nums  \\\n",
       "0  George Popadopoulos Judiciary Committee Transc...         0   \n",
       "1  Scientists Will Spray Particles Into the Sky t...         0   \n",
       "2  We Are Change confronted Joe Biden in 2007 abo...         0   \n",
       "3  Jeff Sessions swats creepy Uncle Joe's hands away         0   \n",
       "4  NXIVM cultist (üçï gate) admits to enslaving wom...         0   \n",
       "\n",
       "                                            combined  binary_text  \n",
       "0  George Popadopoulos Judiciary Committee Transc...            0  \n",
       "1  Scientists Will Spray Particles Into the Sky t...            0  \n",
       "2  We Are Change confronted Joe Biden in 2007 abo...            0  \n",
       "3  Jeff Sessions swats creepy Uncle Joe's hands away            0  \n",
       "4  NXIVM cultist (üçï gate) admits to enslaving wom...            0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from class NLP I\n",
    "def review_to_words(raw_review):\n",
    "    # 1. Remove non-letters.\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_review)\n",
    "    \n",
    "    #3. tokenize the script\n",
    "    tokens = tokenizer.tokenize(letters_only)\n",
    "    \n",
    "    #4. stem the words\n",
    "    clean_stems = [p_stemmer.stem(w) for w in tokens]\n",
    "    \n",
    "    # 5. Join the words back into one string separated by space \n",
    "    return(\" \".join(clean_stems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column with transformed title\n",
    "stem_title = [review_to_words(text) for text in df['title']]\n",
    "df['stemmed_title']= stem_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column with transformed combined data\n",
    "stem_combined = [review_to_words(text) for text in df['combined']]\n",
    "df['stemmed_combined']= stem_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDA on dt classifier to know what to gridsearch for modeling\n",
    "cvec = CountVectorizer(stop_words = 'english')\n",
    "dt = DecisionTreeClassifier()\n",
    "X = df['stemmed_combined']\n",
    "y = df['cat_nums']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                   random_state=25,\n",
    "                                                   stratify=y)\n",
    "X_tr_cv = cvec.fit_transform(X_train)\n",
    "dt.fit(X_tr_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "9957\n"
     ]
    }
   ],
   "source": [
    "# max depth\n",
    "print(dt.tree_.max_depth)\n",
    "print(dt.tree_.n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gathered data from running the above code\n",
    "# will use to hone features on gridsearch\n",
    "# title             n_features: 4939,  depth: 206\n",
    "# stemmed_title     n_features: 3757,  depth: 154\n",
    "# combined          n_features: 14874, depth: 63\n",
    "# stemmed_combined  n_features: 9957,  depth: 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load out file ready to model\n",
    "df.to_csv('./data/final_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
